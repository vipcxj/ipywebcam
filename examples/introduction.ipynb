{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebcam import WebCamWidget, WebCamRecorder, Record, RecordPlayer, FileListFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = FileListFactory(\"test\", \"$i4-$Y-$m-$d-$H-${M}-${S}-$f-$uh6.mp4\", condition=FileListFactory.create_frame_based_condition(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 59 records\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "This is a exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m factory\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m factory:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     r\u001b[38;5;241m.\u001b[39mset_statistics_meta_item(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_range\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m30\u001b[39m])\n\u001b[0;32m     13\u001b[0m     r\u001b[38;5;241m.\u001b[39mset_statistics_meta_item(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_range\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m20\u001b[39m])\n",
      "File \u001b[1;32mD:\\project\\github\\ipywebcam\\ipywebcam\\recorder.py:437\u001b[0m, in \u001b[0;36mRecord.read\u001b[1;34m(self, transformers, fix_time)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transformer \u001b[38;5;129;01min\u001b[39;00m video_transformers:\n\u001b[1;32m--> 437\u001b[0m         frame \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transformer \u001b[38;5;129;01min\u001b[39;00m audio_transformers:\n",
      "File \u001b[1;32mD:\\project\\github\\ipywebcam\\ipywebcam\\recorder.py:60\u001b[0m, in \u001b[0;36mRecordFrameTransformer.transform\u001b[1;34m(self, frame, record)\u001b[0m\n\u001b[0;32m     57\u001b[0m time_base \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mtime_base\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__use_context:\n\u001b[1;32m---> 60\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__use_record:\n\u001b[0;32m     62\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__callback(frame, record)\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36madd_random_stats\u001b[1;34m(frame, record, ctx)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_random_stats\u001b[39m(frame, record: Record, ctx):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is a exception\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     record\u001b[38;5;241m.\u001b[39mset_statistics(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest1\u001b[39m\u001b[38;5;124m'\u001b[39m, frame\u001b[38;5;241m.\u001b[39mtime, random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m30\u001b[39m), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     record\u001b[38;5;241m.\u001b[39mset_statistics(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest2\u001b[39m\u001b[38;5;124m'\u001b[39m, frame\u001b[38;5;241m.\u001b[39mtime, random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m15\u001b[39m), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mException\u001b[0m: This is a exception"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def add_random_stats(frame, record: Record, ctx):\n",
    "    record.set_statistics('test1', frame.time, random.randint(0, 30), flush=False)\n",
    "    record.set_statistics('test2', frame.time, random.randint(0, 15), flush=False)\n",
    "    record.set_statistics('test3', frame.time, random.randint(-10, 10), flush=False)\n",
    "transformer = Record.create_video_frame_transformer(add_random_stats)\n",
    "\n",
    "factory.load()\n",
    "for r in factory:\n",
    "    r.read([transformer])\n",
    "    r.set_statistics_meta_item('test1', 'y_range', [0, 30])\n",
    "    r.set_statistics_meta_item('test2', 'y_range', [-5, 20])\n",
    "    r.set_statistics_meta_item('test3', 'y_range', [-5, 20])\n",
    "factory.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9042fa35558c4c6393126c147c5c5f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<super: ipywebcam.webcam.WebCamWidget,\n",
       "        WebCamWidget(constraints={'video': {'frameRate': {'max': 10}, 'width': 256, 'height': 192}}, iceServers=[{'urls': 'turn:190.92.221.222', 'username': 'admin', 'credential': '123456'}])>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40852809c06a4da5b3b6ebe8387fa52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = WebCamWidget(\n",
    "    iceServers=[{\"urls\": \"turn:190.92.221.222\", \"username\": \"admin\", \"credential\": \"123456\"}],\n",
    "    constraints={\n",
    "        \"video\": {\n",
    "            \"frameRate\": { \"max\": 10 },\n",
    "            \"width\": 256,\n",
    "            \"height\": 192,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = WebCamRecorder(w, factory)\n",
    "recorder.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from ipywebcam import ContextHelper\n",
    "from av import VideoFrame\n",
    "array = []\n",
    "async def transform(frame, ctx):\n",
    "    async with ContextHelper(ctx) as helper:\n",
    "        if helper.is_first_time_meet():\n",
    "            print(\"first time\")\n",
    "        if helper.is_first_time_meet():\n",
    "            print(\"first time\")\n",
    "        if helper.is_frame_passed(70):\n",
    "            print(\"70 frame has passed\")\n",
    "        if helper.is_frame_passed(70):\n",
    "            print(\"70 frame has passed\")\n",
    "        if helper.is_time_passed(10):\n",
    "            print(\"10 second has passed\")\n",
    "        if helper.is_time_passed(10):\n",
    "            print(\"10 second has passed\")\n",
    "        img = frame.to_ndarray(format=\"bgr24\")\n",
    "        # prepare color\n",
    "        img_color = cv2.pyrDown(cv2.pyrDown(img))\n",
    "        for _ in range(6):\n",
    "            img_color = cv2.bilateralFilter(img_color, 9, 9, 7)\n",
    "        img_color = cv2.pyrUp(cv2.pyrUp(img_color))\n",
    "\n",
    "        # prepare edges\n",
    "        img_edges = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img_edges = cv2.adaptiveThreshold(\n",
    "            cv2.medianBlur(img_edges, 7),\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            9,\n",
    "            2,\n",
    "        )\n",
    "        img_edges = cv2.cvtColor(img_edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # combine color and edges\n",
    "        img = cv2.bitwise_and(img_color, img_edges)\n",
    "\n",
    "        # rebuild a VideoFrame, preserving timing information\n",
    "        new_frame = VideoFrame.from_ndarray(img, format=\"bgr24\")\n",
    "        # new_frame.pts = frame.pts\n",
    "        # new_frame.time_base = frame.time_base\n",
    "        return new_frame\n",
    "\n",
    "transformer = w.add_video_transformer(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.remove_video_transformer(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.close_peers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 59 records\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import cv2\n",
    "from av import VideoFrame\n",
    "from ipywebcam import ContextHelper\n",
    "logger = logging.getLogger('ipywebcam')\n",
    "recorder = WebCamRecorder(None, factory)\n",
    "recorder.factory.load()\n",
    "print(recorder.factory.record_count())\n",
    "player = RecordPlayer(recorder=recorder)\n",
    "player.loop = True\n",
    "def create_transform(channel):\n",
    "    def transform(frame, r, ctx):\n",
    "        with ContextHelper(ctx) as helper:\n",
    "            if helper.is_frame_passed(30):\n",
    "                print(id(channel))\n",
    "            img = frame.to_ndarray(format=\"bgr24\")\n",
    "            # prepare color\n",
    "            img_color = cv2.pyrDown(cv2.pyrDown(img))\n",
    "            for _ in range(6):\n",
    "                img_color = cv2.bilateralFilter(img_color, 9, 9, 7)\n",
    "            img_color = cv2.pyrUp(cv2.pyrUp(img_color))\n",
    "\n",
    "            # prepare edges\n",
    "            img_edges = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            img_edges = cv2.adaptiveThreshold(\n",
    "                cv2.medianBlur(img_edges, 7),\n",
    "                255,\n",
    "                cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                cv2.THRESH_BINARY,\n",
    "                9,\n",
    "                2,\n",
    "            )\n",
    "            img_edges = cv2.cvtColor(img_edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # combine color and edges\n",
    "            img = cv2.bitwise_and(img_color, img_edges)\n",
    "\n",
    "            # rebuild a VideoFrame, preserving timing information\n",
    "            new_frame = VideoFrame.from_ndarray(img, format=\"bgr24\")\n",
    "            # new_frame.pts = frame.pts\n",
    "            # new_frame.time_base = frame.time_base\n",
    "            return new_frame\n",
    "    return transform\n",
    "transformers = {}\n",
    "for channel in [\"test1\", \"test2\", \"test3\"]:\n",
    "    transform = create_transform(channel)\n",
    "    transformers[channel] = player.add_video_transformer(transform, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel, transformer in transformers.items():\n",
    "    player.remove_transformer(transformer, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84458a7dc7a428f862ee3f3f5051bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<super: ipywebcam.recorder.RecordPlayer,\n",
       "        RecordPlayer(loop=True, selected_range=[0.0, 0.0])>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0185c23b053e46dda1049bb9604211c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d73576d969b418d8927663f2e67c992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'traceback': ['\\x1b[1;31m--------------------------------------------------------------------…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 7.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.selected_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2}\n",
      "{'a': 1}\n"
     ]
    }
   ],
   "source": [
    "a = { \"a\":1, \"b\":2}\n",
    "print(a)\n",
    "del a[\"b\"]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\a\\b\\c\n",
      "\\a\\b\\c\n",
      "..\\b\\c\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "print(path.normpath('\\\\a\\\\b\\\\c'))\n",
    "print(path.normpath('/a/b/c'))\n",
    "p = path.relpath(path.normpath('a/b/c'), path.normpath('a/d'))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-32730' coro=<some_async_function() running at C:\\Users\\cxj\\AppData\\Local\\Temp\\ipykernel_11156\\2957130310.py:2>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "async def some_async_function():\n",
    "    for i in range(0, 10):\n",
    "        print(i)\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(some_async_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
